[{"categories":["面试"],"content":"简单实现 寻找两个正序数组的中位数可以通过归并排序的思想，先将两个数组合并为一个有序数组，然后根据数组的长度是奇数还是偶数来找出中位数。以下是一个简单的实现： package main import \"fmt\" func findMedianSortedArrays(nums1 []int, nums2 []int) float64 { mergedNums := merge(nums1, nums2) length := len(mergedNums) if length%2 == 0 { return float64(mergedNums[length/2-1]+mergedNums[length/2]) / 2.0 } else { return float64(mergedNums[length/2]) } } func merge(nums1 []int, nums2 []int) []int { merged := make([]int, len(nums1)+len(nums2)) i, j, k := 0, 0, 0 for i \u003c len(nums1) \u0026\u0026 j \u003c len(nums2) { if nums1[i] \u003c nums2[j] { merged[k] = nums1[i] i++ } else { merged[k] = nums2[j] j++ } k++ } for i \u003c len(nums1) { merged[k] = nums1[i] i++ k++ } for j \u003c len(nums2) { merged[k] = nums2[j] j++ k++ } return merged } func main() { nums1 := []int{1, 3} nums2 := []int{2} fmt.Println(findMedianSortedArrays(nums1, nums2)) // 输出: 2 nums1 = []int{1, 2} nums2 = []int{3, 4} fmt.Println(findMedianSortedArrays(nums1, nums2)) // 输出: 2.5 } ","date":"2024-03-19","objectID":"/%E5%AF%BB%E6%89%BE%E4%B8%A4%E4%B8%AA%E6%AD%A3%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E4%BD%8D%E6%95%B0/:1:0","tags":["面试"],"title":"寻找两个正序数组中位数","uri":"/%E5%AF%BB%E6%89%BE%E4%B8%A4%E4%B8%AA%E6%AD%A3%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E4%BD%8D%E6%95%B0/"},{"categories":["面试"],"content":"二分查找 package main import ( \"fmt\" \"math\" ) func findMedianSortedArrays(nums1 []int, nums2 []int) float64 { if len(nums1) \u003e len(nums2) { // 首先确保nums1不比nums2长 nums1, nums2 = nums2, nums1 } m, n := len(nums1), len(nums2) imin, imax, halfLen := 0, m, (m+n+1)/2 for imin \u003c= imax { i := (imin + imax) / 2 j := halfLen - i // 二分查找在nums1中找到一个位置i，使得nums1[i-1] \u003c= nums2[j]和nums2[j-1] \u003c= nums1[i] if i \u003c m \u0026\u0026 nums2[j-1] \u003e nums1[i] { imin = i + 1 } else if i \u003e 0 \u0026\u0026 nums1[i-1] \u003e nums2[j] { imax = i - 1 } else { var maxOfLeft float64 if i == 0 { // nums1都在右边，maxOfLeft在nums2 maxOfLeft = float64(nums2[j-1]) } else if j == 0 { maxOfLeft = float64(nums1[i-1]) } else { maxOfLeft = math.Max(float64(nums1[i-1]), float64(nums2[j-1])) } if (m+n)%2 == 1 { // 奇数, 返回中间位置 return maxOfLeft } var minOfRight float64 if i == m { // nums1都在左边，minOfRight在nums2 minOfRight = float64(nums2[j]) } else if j == n { minOfRight = float64(nums1[i]) } else { minOfRight = math.Min(float64(nums1[i]), float64(nums2[j])) } return (maxOfLeft + minOfRight) / 2.0 } } return 0 } func main() { nums1 := []int{1, 3} nums2 := []int{2} fmt.Println(findMedianSortedArrays(nums1, nums2)) // 输出: 2 nums1 = []int{1, 2} nums2 = []int{3, 4} fmt.Println(findMedianSortedArrays(nums1, nums2)) // 输出: 2.5 } 这个问题的关键在于理解我们正在寻找什么。我们需要找到两个数组中的中位数，也就是说，我们需要找到一个位置，使得左边的所有元素都小于右边的所有元素，并且左边的元素数量等于右边的元素数量（当总数为偶数时）或者多一个（当总数为奇数时）。 为了找到这个位置，我们可以使用二分查找的方法。我们首先在较短的数组中找到一个位置i，然后在较长的数组中找到一个位置j，使得j = (m+n+1)/2 - i。这样，我们就可以保证左边的元素数量等于右边的元素数量（当总数为偶数时）或者多一个（当总数为奇数时）。 然后，我们需要检查这个位置是否满足条件，也就是说，我们需要检查nums1[i-1]是否\u003c= nums2[j]，并且nums2[j-1]是否\u003c= nums1[i]。如果满足条件，那么我们就找到了正确的位置。如果不满足条件，那么我们就需要调整i的位置，如果nums1[i-1]大于nums2[j]，那么我们需要减小i的值（imax = i - 1），如果nums2[j-1]大于nums1[i]，那么我们需要增大i的值(imin = i + 1)。 最后，当我们找到正确的位置后，我们就可以计算中位数了。如果总数为奇数，那么中位数就是左边的最大值，也就是max(nums1[i-1], nums2[j-1])。如果总数为偶数，那么中位数就是左边的最大值和右边的最小值的平均值，也就是(max(nums1[i-1], nums2[j-1]) + min(nums1[i], nums2[j])) / 2。 这个方法的时间复杂度为O(log(min(m, n)))，其中m和n分别是两个数组的长度，因为我们每次都在较短的数组中进行二分查找，所以时间复杂度取决于较短的数组的长度。 ","date":"2024-03-19","objectID":"/%E5%AF%BB%E6%89%BE%E4%B8%A4%E4%B8%AA%E6%AD%A3%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E4%BD%8D%E6%95%B0/:2:0","tags":["面试"],"title":"寻找两个正序数组中位数","uri":"/%E5%AF%BB%E6%89%BE%E4%B8%A4%E4%B8%AA%E6%AD%A3%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E4%BD%8D%E6%95%B0/"},{"categories":["面试"],"content":"边界情况考虑 当i为0时，表示nums1的所有元素都在右侧，此时左侧的最大值应该是nums2[j-1]。 当i为m（nums1的长度）时，表示nums1的所有元素都在左侧，此时右侧的最小值应该是nums2[j]。 当j为0时，表示nums2的所有元素都在右侧，此时左侧的最大值应该是nums1[i-1]。 当j为n（nums2的长度）时，表示nums2的所有元素都在左侧，此时右侧的最小值应该是nums1[i]。 ","date":"2024-03-19","objectID":"/%E5%AF%BB%E6%89%BE%E4%B8%A4%E4%B8%AA%E6%AD%A3%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E4%BD%8D%E6%95%B0/:2:1","tags":["面试"],"title":"寻找两个正序数组中位数","uri":"/%E5%AF%BB%E6%89%BE%E4%B8%A4%E4%B8%AA%E6%AD%A3%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E4%BD%8D%E6%95%B0/"},{"categories":["go"],"content":"template 动作(Action) 插值(Interpolation) {{ . }} // 输出当前对象 {{ .FieldName }} // 访问当前对象的字段或方法 管道(Pipelines) 可以将一个函数的输出作为另一个函数的输入 {{ .Title | toUpper | printf \"%s is the title\" }} // 首先将.Title转化为大写，然后格式输出 控制结构(Control Structures) 条件语句 {{ if .IsTrue }} // 如果.IsTrue为真，则执行这里的代码 ... {{ else }} // 否则，执行这里的代码 ... {{ end }} 循环语句 {{ range .Items }} // 迭代.Items切片的每一项 ... {{ end }} 变量(Variables) 在模板中声明和使用局部变量 {{ $x := .Var }} // 声明变量$x 并赋值为.Var 模板引用(Template Reference) 在一个模板中调用另一个模板 {{ template \"name\" . }} // 包含模板\"name\" 注释(Comments) 在模板中添加注释 {{/* 这是一条注释 */}} // A Comment ","date":"2024-03-14","objectID":"/go-template/:0:1","tags":["go"],"title":"Go template","uri":"/go-template/"},{"categories":["go"],"content":"边界检查 go在array/slice元素的索引和subslice 操作中，运行时将检查所涉及的索引是否越界–边界检查(Bounds-checking)。如果一个指数超出了范围，就会产生panic ，以防止非法的index造成伤害（如Heartbleed）。边界检查使我们的代码安全运行，另一方面，它们也使我们的代码运行得慢一些。可以通过生成的汇编代码，查看是否有插入检查 CALL runtime.panicIndex(SB). 这种插入的跳转会影响我们能多大程度上利用cpu的pipelining。 Go语言的BCE技术是基于静态代码分析的SSA。SSA是静态单赋值形式（Static Single Assignment）的缩写，这是一种中间表示（Intermediate Representation，IR）的形式，用于进行编译器优化。这种技术的目标是在编译时期尽可能地消除数组边界检查，以提高代码的运行效率。SSA帮助Go编译器有效地使用BCE(Found IsInBounds elimination)和CSE(common subexpression elimination)等优化。BCE可以避免一些不必要的边界检查，CSE可以避免一些重复计算，使标准Go编译器可以生成更高效的程序。 我们可以使用-gcflags=\"-d=ssa/check_bce/debug=1\"，查看哪些代码插入了【边界检查】，-d=ssa/check_bce/debug=1选项会让编译器打印出SSA阶段的详细信息，包括进行边界检查消除（BCE）的决策。 ","date":"2024-02-24","objectID":"/go-bec/:1:0","tags":["go"],"title":"Go BEC介绍和实际应用","uri":"/go-bec/"},{"categories":["go"],"content":"常见边界消除方法 总的来说，至于能否进行 BCE 优化，主要取决于我们的代码是否能在编译阶段给编译器足够的信息(hints)来确认哪些访问是安全的。这边介绍几个我认为比较有用的例子： ","date":"2024-02-24","objectID":"/go-bec/:2:0","tags":["go"],"title":"Go BEC介绍和实际应用","uri":"/go-bec/"},{"categories":["go"],"content":"例子1：先索引最大下标 func s2l(s []int) { _ = s[0] // Found IsInBounds _ = s[1] // Found IsInBounds _ = s[2] // Found IsInBounds } // BCE func l2s(s []int) { _ = s[2] // Found IsInBounds _ = s[1] // BCE _ = s[0] // BCE } 显然如果最大下标check通过，那么就不需要往下check了。 ","date":"2024-02-24","objectID":"/go-bec/:2:1","tags":["go"],"title":"Go BEC介绍和实际应用","uri":"/go-bec/"},{"categories":["go"],"content":"例子2：如果明确数组长度，请显式写出 func fixLen(a [5]int) { // 当这样写：a []int 下面就不能BCE _ = a[4] // BCE } ","date":"2024-02-24","objectID":"/go-bec/:2:2","tags":["go"],"title":"Go BEC介绍和实际应用","uri":"/go-bec/"},{"categories":["go"],"content":"例子3：使用掩码进行索引 func maskI(src []int, i int) { i := i \u0026 uint64(len(src) - 1) _ = src[i] } ","date":"2024-02-24","objectID":"/go-bec/:2:3","tags":["go"],"title":"Go BEC介绍和实际应用","uri":"/go-bec/"},{"categories":["go"],"content":"实际例子 ","date":"2024-02-24","objectID":"/go-bec/:3:0","tags":["go"],"title":"Go BEC介绍和实际应用","uri":"/go-bec/"},{"categories":["go"],"content":"点积函数优化 sourcegraph的工程师在他们的点积计算函数优化1上使用了BCE技术， 这个是BCE之前版本： func DotUnroll4(a, b []float32) float32 { sum := float32(0) for i := 0; i \u003c len(a); i += 4 { s0 := a[i] * b[i] s1 := a[i+1] * b[i+1] s2 := a[i+2] * b[i+2] s3 := a[i+3] * b[i+3] sum += s0 + s1 + s2 + s3 } return sum } 这个是BCE之后版本： func DotBCE(a, b []float32) float32 { if len(a) != len(b) { panic(\"slices must have equal lengths\") } if len(a)%4 != 0 { panic(\"slice length must be multiple of 4\") } sum := float32(0) for i := 0; i \u003c len(a); i += 4 { aTmp := a[i : i+4 : i+4] bTmp := b[i : i+4 : i+4] s0 := aTmp[0] * bTmp[0] s1 := aTmp[1] * bTmp[1] s2 := aTmp[2] * bTmp[2] s3 := aTmp[3] * bTmp[3] sum += s0 + s1 + s2 + s3 } return sum } 编译看看： go build -gcflags=\"-d=ssa/check_bce/debug=1\" # learngo/bce ./dot.go:6:10: Found IsInBounds ./dot.go:6:17: Found IsInBounds ./dot.go:7:10: Found IsInBounds ./dot.go:7:19: Found IsInBounds ./dot.go:8:10: Found IsInBounds ./dot.go:8:19: Found IsInBounds ./dot.go:9:10: Found IsInBounds ./dot.go:9:19: Found IsInBounds ./dot.go:26:12: Found IsSliceInBounds ./dot.go:27:12: Found IsSliceInBounds 边界检查从8个下降到了2两个，因为新的slice的len和cap都是4,可以确保aTemp[0]、aTemp[3]、bTemp[0]、bTemp[3]不会越界。 这边比较有趣的是：为什么使用 a[i:i+4:i+4] 而不是 a[i:i+4]? – 指定cap可以减少编译器重新计算slice的cap, 从而提高性能 ","date":"2024-02-24","objectID":"/go-bec/:3:1","tags":["go"],"title":"Go BEC介绍和实际应用","uri":"/go-bec/"},{"categories":["go"],"content":"业务函数 首先我使用的go版本为1.21, 游戏商品推荐场景中，我们经常需要对新品道具做置顶操作。现在假设我们有个pkgs []*Pkg slice, 需要对新品ExtInfo[“IsNew”]==“1” 做置顶操作，其中相关删除操作应该已经是最优解了： type Pkg struct { Id string ExtInfo map[string]string } func TopNewItemsBce0(pkgs []*Pkg) []*Pkg { topPkgs := make([]*Pkg, 0) for i := 0; i \u003c len(pkgs); i++ { if v, ok := pkgs[i].ExtInfo[\"IsNew\"]; ok \u0026\u0026 v == \"1\" { // 方式1,推荐 topPkgs = append(topPkgs, pkgs[i]) pkgs = append(pkgs[:i], pkgs[i+1:]...) i-- } } outPkgs := append(topPkgs, pkgs...) return outPkgs } func TopNewItemsBce1(pkgs []*Pkg) []*Pkg { topPkgs := make([]*Pkg, 0) for i := 0; i \u003c len(pkgs); i++ { if pkgs[i].ExtInfo[\"IsNew\"] == \"1\" { // 方式2，不推荐 topPkgs = append(topPkgs, pkgs[i]) pkgs = append(pkgs[:i], pkgs[i+1:]...) i-- } } outPkgs := append(topPkgs, pkgs...) return outPkgs } 其中涉及到条件的判断，写法有下面两种： if v, ok := pkgs[i].ExtInfo[\"IsNew\"]; ok \u0026\u0026 v == \"1\" {} if pkgs[i].ExtInfo[\"IsNew\"] == \"1\" {}， 这两种写法有啥区别吗？ 我们用go build -gcflags=\"-d=ssa/check_bce/debug=1\" 检测一下 bec检查 发现TopNewItemsBce1在 ExtInfo[\"IsNew\"]处多了一个边界检查，pkgs[i] 这边不可避免要做一次BC, 因为在下面有对i--，虽然我们知道这个地方没有数组越界的风险，但是go编译器目前并不能进行BCE! ","date":"2024-02-24","objectID":"/go-bec/:3:2","tags":["go"],"title":"Go BEC介绍和实际应用","uri":"/go-bec/"},{"categories":["go"],"content":"test 我们使用generateTestPackages生成1000（游戏商品一般个数很少），每一百个设置一个新品，然后跑一下Benchmark看看 func generateTestPackages() []*Pkg { pkgs := make([]*Pkg, 0) for i := 0; i \u003c 1000; i++ { // Generate 1000 packages for testing pkg := \u0026Pkg{ Id: strconv.Itoa(i), ExtInfo: make(map[string]string), } if i%100 == 0 { pkg.ExtInfo[\"IsNew\"] = \"1\" } else { pkg.ExtInfo[\"IsNew\"] = \"0\" } pkgs = append(pkgs, pkg) } return pkgs } func BenchmarkTopNewItemsBce0(b *testing.B) { mixPkgs := generateTestPackages() // You need to implement this function to generate test data b.ResetTimer() for i := 0; i \u003c b.N; i++ { TopNewItemsBce0(mixPkgs) } } func BenchmarkTopNewItemsBce1(b *testing.B) { mixPkgs := generateTestPackages() // You need to implement this function to generate test data b.ResetTimer() for i := 0; i \u003c b.N; i++ { TopNewItemsBce1(mixPkgs) } } 在我的开发机上测试，二者的性能差的竟然有要一倍！ goos: linux goarch: amd64 pkg: learngo/bce cpu: AMD EPYC 7K62 48-Core Processor BenchmarkTopNewItemsBce0 BenchmarkTopNewItemsBce0-16 85531 14188 ns/op 8192 B/op 1 allocs/op BenchmarkTopNewItemsBce1 BenchmarkTopNewItemsBce1-16 48134 24912 ns/op 8192 B/op 1 allocs/op 所以，对于判断map中每个key取值是不是符合我们的预期，我们最好是使用v, ok := map[key]; ok \u0026\u0026 v == 这种形式。 ","date":"2024-02-24","objectID":"/go-bec/:3:3","tags":["go"],"title":"Go BEC介绍和实际应用","uri":"/go-bec/"},{"categories":["go"],"content":"1brc 1brc github很火的一个Java “十亿行挑战”（1BRC）\" . 虽然该 任务要求使用java完成挑战，但是很多开发者也用其他语言实现了一下，比如go、c++。我们可以看到Alexander Yastrebov’s（之前go版本最快的实现 2.9s）其中也用了BCE进行代码性能优化—给编译器明确不会越界的信息 ... // keep short and inlinable getMeasurement := func(hash uint64, value []byte) *measurement { i := hash \u0026 uint64(entriesSize-1) entry := \u0026entries[i] // 通过上面hash \u0026 uint64(entriesSize-1)可知 i \u003c entriesSize ... Ben Hoyt 在他的文章2中描述了他从最初的简单未优化版本（耗时1分45秒）到最终的优化并行版本（耗时仅3.4秒）的九个不同解决方案, 其中很多点还是很值得看看的，特别是对于处理大量数据的程序，比如： 使用指针值的map：通过使用map[string]*stats而不是map[string]stats，可以减少哈希操作的次数，因为更新map时不需要重复哈希。 手工解析数据：避免使用标准库中的strconv.ParseFloat，而是编写自定义的解析函数来处理简单的数字格式，这样可以减少不必要的错误处理和复杂性。 固定点整数：对于只有单个小数位的温度数据，使用固定点整数代替浮点数可以提高性能，因为整数运算通常比浮点运算更快。 避免使用bytes.Cut：通过从字符串末尾开始解析温度，而不是使用bytes.Cut从开头查找分隔符，可以减少不必要的字符串遍历。 避免bufio.Scanner：通过直接读取文件块并手动处理每一行，可以避免bufio.Scanner的额外开销，这样可以更有效地处理数据。 自定义哈希表：实现一个自定义的哈希表可以提高查找和插入的效率，尤其是当标准库的map操作成为性能瓶颈时。 并行处理：将文件分割成多个块，并使用多个goroutine并行处理每个块，然后合并结果，可以显著提高处理速度，尤其是在多核处理器上。 内存映射文件：虽然文章中没有使用，但提到了内存映射文件作为一种优化手段，这可以减少磁盘I/O操作，尤其是在处理大型文件时。 代码剖析和性能分析：使用Go的剖析工具（如pprof）来识别代码中的瓶颈，并针对性地进行优化。 简化数据结构：通过合理设计数据结构，例如使用数组或切片代替map，可以在某些情况下提高性能。 他在最后提了一个问题： Why does if items[hashIndex].key == nil show as taking 5.01s, but the call to bytes.Equal shows as only 390ms. Surely a slice lookup is much cheaper than a function call? 插入了边界检查 详细看了一下这个items[hashIndex].key == nil地方的汇编代码，可以看到这边进行了边界检查 我们通过使用Alexander Yastrebov一样的BCE方法，来看看优化之后的cpu pprof source 性能 BCE之后 所以Ben Hoyt提的问题的原因应该就是go因为边界检查带来的影响。 这边提一下：当我尝试BCE之后原来Ben Hoyt的r9版本在我Linux机器跑到了3s以内，但是在运行完Alexander Yastrebov’s的mmp版本之后，优化后的和r9版本跑的时间就基本上差不多了，百思不得其解。可惜当时忘了保存3s(印象是2.6s 好像提升的有点离谱)以内的截图。 后面我重新在windows机器（Intel(R) Core(TM) i7-10700 CPU @ 2.90GHz 32G内存）上测试了一下，大概有3%的提升。 ","date":"2024-02-24","objectID":"/go-bec/:4:0","tags":["go"],"title":"Go BEC介绍和实际应用","uri":"/go-bec/"},{"categories":["go"],"content":"小结 更多例子可以参考：2和3，可以看出是否能BCE是需要一些实践验证的，并且BCE之后性能并不一定就有提升。 参考： https://sourcegraph.com/blog/slow-to-simd ↩︎ https://benhoyt.com/writings/go-1brc/ ↩︎ ↩︎ https://go101.org/optimizations/5-bce.html ↩︎ ","date":"2024-02-24","objectID":"/go-bec/:5:0","tags":["go"],"title":"Go BEC介绍和实际应用","uri":"/go-bec/"},{"categories":["flink"],"content":"Apache Flink 中的 Network Stack 是其流式处理引擎的主要组件之一，它负责在分布式系统中进行数据交换和通信。 数据传输方式: 在Flink中，数据通过网络在任务操作符之间传输。Flink 网络堆栈使用 TCP/IP 套接字进行传输，并为每个连接配备了两个缓冲池。一个用于数据的接收，一个用于数据的发送。 Credit-based Flow Control: Flink 网络堆栈采用信用基础流程控制机制，以解决背压和数据拥堵问题。它允许接收者通过控制 “credit” 数量来动态调整其数据接收速度。 序列化和反序列化: 网络层将数据以序列化的方式传输，从而可以在不同的机器之间进行交换。然后，在接收方，数据被反序列化并通过 Record Deserializer 转化为 Java 对象。 Large Records Handling: Flink 对于处理大记录采用了特殊的处理方式。例如，如果一条记录不能完全地装入一个网络缓冲区，那么 Flink 会将这条记录分成多个较小的片段进行传输。 交互性和异步性: Flink Network Stack 采用异步和非阻塞的设计，以支持高吞吐量，并减少任务在数据读取和处理时的等待时间。 缓冲与排队: 法律在发送和接收侧都使用了缓冲区和队列，以优化网络传输。 可扩展性和容错性: Flink 的网络堆栈被设计为能够支持大量的网络连接，并且在出现网络故障时，它能够通过内部机制进行恢复。 ","date":"2024-02-21","objectID":"/flink-network-stack/:0:0","tags":null,"title":"Flink Network Stack","uri":"/flink-network-stack/"},{"categories":["flink"],"content":"Credit-based Flow Control Credit-based Flow Control 是 Apache Flink 从 1.5 版本开始引入的特性，主要用于解决数据背压(backpressure)问题。它基于生产者-消费者模型，允许消费者控制其接收数据的速度。 实现这种流控制的基本思想是“credit”。Credit代表了接收者可以处理的数据量。作为发送者的任务可能会有很多缓冲区中预填充了数据要发送，但是它只有在确认接收者有足够的credit（即有足够的空间接收新数据），才会真正发送数据。 下面是 Credit-based Flow Control 的基本工作流程： 初始化：算子启动时，接收者（下游任务）分配给每个发送者（上游任务）一定数量的初始credit。 数据发送：只有当发送者检查到目标接收者还有剩余credit时，才会把数据发送出去。每发送一个网络缓冲区的数据，就会消耗掉一份credit。 credit的返还：当接收者消耗了一个网络缓冲区中的数据，它就会向发送者返还一份credit。这表示接收者已经准备好接收新的数据了。 数据拥塞与背压：如果接收者处理不过来输入的数据，它的credit就会逐渐减少。当所有credit用完时，发送者将停止数据的发送，等待新的credit。这样就形成了一种自我调节的机制，发送者不能无限制地生产数据，而是要根据消费者的处理能力调整速率。 ","date":"2024-02-21","objectID":"/flink-network-stack/:1:0","tags":null,"title":"Flink Network Stack","uri":"/flink-network-stack/"},{"categories":["flink"],"content":"Apache Flink 实现 exactly-once 语义步骤： 快照（Snapshot）：Flink 使用一种称为 “异步分布式快照” 的技术来捕获数据流的状态。这种技术基于 Chandy-Lamport 算法，可以在不阻塞数据流处理的情况下，捕获数据流的一致性状态。 重放（Replay）：当系统出现故障时，Flink 可以从最近的快照开始重放数据流，以恢复到故障发生前的状态。这种重放机制确保了数据处理的一致性。 端到端的一致性保证：Flink 不仅在内部保证了 exactly-once 语义，还通过与外部系统（如 Kafka）的集成，实现了端到端的 exactly-once 语义。例如，Flink 可以与 Kafka 集成，使用 Kafka 的事务功能来确保数据的一致性。 两阶段提交协议（Two-Phase Commit Protocol）：Flink 还使用了两阶段提交协议来保证 exactly-once 语义。在第一阶段，所有的操作都被预提交并保存在快照中。只有当所有的操作都成功预提交后，才会进入第二阶段，即提交阶段。在提交阶段，所有的操作都会被正式提交。如果在预提交阶段有任何操作失败，那么整个事务都会被回滚，从而保证了数据的一致性。 ","date":"2024-02-21","objectID":"/flink%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0exactly-one-%E8%AF%AD%E4%B9%89%E7%9A%84/:1:0","tags":["flink"],"title":"flink是如何实现exactly-one 语义的","uri":"/flink%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0exactly-one-%E8%AF%AD%E4%B9%89%E7%9A%84/"},{"categories":["flink"],"content":"快照技术 Apache Flink 使用的快照技术是基于 Chandy-Lamport 分布式快照算法的。下面是这个快照技术的一些关键点： 异步：Flink 的快照技术是异步的，这意味着它不会阻塞数据流的处理。当系统需要创建一个快照时，它会在数据流中插入一个特殊的标记，称为 “barrier”。当每个操作符接收到这个 barrier 时，它会记录下当前的状态，然后继续处理数据流。这样，系统可以在不停止数据流处理的情况下，捕获数据流的状态。 分布式：Flink 的快照技术是分布式的，这意味着它可以在分布式系统中工作。每个操作符都会独立地记录自己的状态，然后这些状态会被收集起来，形成一个全局的快照。这个全局的快照代表了数据流在某一时刻的状态。 一致性：尽管 Flink 的快照技术是异步和分布式的，但它仍然可以保证快照的一致性。这是因为，当所有的操作符都接收到同一个 barrier 时，它们记录的状态是一致的。这样，即使在分布式系统中，也可以创建出一致的快照。 故障恢复：当系统出现故障时，Flink 可以使用快照来恢复数据流的状态。系统会从最近的快照开始，重放数据流，以恢复到故障发生前的状态。这种重放机制确保了数据处理的一致性。 ","date":"2024-02-21","objectID":"/flink%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0exactly-one-%E8%AF%AD%E4%B9%89%E7%9A%84/:2:0","tags":["flink"],"title":"flink是如何实现exactly-one 语义的","uri":"/flink%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0exactly-one-%E8%AF%AD%E4%B9%89%E7%9A%84/"},{"categories":["flink"],"content":"重放数据流 在 Flink 中，重放数据流主要是通过从最近的快照开始，重新处理从该快照时间点之后的数据。具体来说，当系统出现故障时，Flink 会找到最近的一次快照，然后从这个快照中恢复每个操作符的状态。接着，Flink 会从数据源开始，重新处理从快照时间点之后的数据。这样，系统就可以恢复到故障发生前的状态。 至于 “操作符的状态”，这主要包括两部分： 内部状态：这是操作符在处理数据流时，内部维护的状态。例如，如果一个操作符是用来计算滑动窗口的平均值，那么它的内部状态可能包括当前窗口的所有元素，以及这些元素的总和。当系统需要创建一个快照时，这个操作符会保存这些内部状态。 输入和输出缓冲区：除了内部状态，操作符还会保存其输入和输出缓冲区的状态。这是因为，当系统恢复时，操作符需要从恰好的位置开始，重新处理数据。因此，它需要知道在快照时，哪些数据已经被处理，哪些数据还在缓冲区中等待处理。 ","date":"2024-02-21","objectID":"/flink%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0exactly-one-%E8%AF%AD%E4%B9%89%E7%9A%84/:3:0","tags":["flink"],"title":"flink是如何实现exactly-one 语义的","uri":"/flink%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0exactly-one-%E8%AF%AD%E4%B9%89%E7%9A%84/"},{"categories":["flink"],"content":"参考 Apache Flink 官方文档：Data Streaming Fault Tolerance Apache Flink 官方博客：A Deep-Dive into Flink’s Network Stack ","date":"2024-02-21","objectID":"/flink%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0exactly-one-%E8%AF%AD%E4%B9%89%E7%9A%84/:4:0","tags":["flink"],"title":"flink是如何实现exactly-one 语义的","uri":"/flink%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0exactly-one-%E8%AF%AD%E4%B9%89%E7%9A%84/"},{"categories":["go"],"content":"内存安全关注防止程序访问非法或未预期的内存空间。Go语言被称为“内存安全的编程语言”，是因为它确保了程序在运行过程中不能自由地访问内存，而是必须按照严格的规则来进行。这样可以防止很多常见的编程错误，比如内存泄漏，悬垂指针，缓冲区溢出等。 具体来说，Go语言中的内存安全主要通过以下方式实现： 垃圾回收：Go 语言有内建的垃圾回收机制，可以自动管理内存，避免手动释放内存导致的内存泄漏。 安全的指针操作：在Go语言中，没有像C/C++中那样的直接的指针运算，降低了程序员操作错误导致的内存问题。 强类型：Go是静态类型语言，它在编译阶段进行类型检查，如果试图将错类型的值赋值给变量，程序将无法编译。这避免了许多类型相关的内存错误。 数据竞态保护：Go提供了数据同步机制（如互斥量Mutex），可以避免在并发条件下发生的数据竞态（race condition）。 内存初始化：在Go中，变量在声明但没有初始化的时候，会被自动赋予零值，因此它不会引入未初始化的内存问题。 ","date":"2024-02-21","objectID":"/go-%E5%86%85%E5%AD%98%E5%AE%89%E5%85%A8/:0:0","tags":["go"],"title":"go 内存安全","uri":"/go-%E5%86%85%E5%AD%98%E5%AE%89%E5%85%A8/"},{"categories":["go"],"content":"未初始化的内存会导致什么可能的问题？ 未初始化的内存可能会导致一系列程序错误，细节上会因具体语言和操作系统的实现有所差异，但通常会引发如下个问题： 未定义行为: 最重要的是，未初始化的内存会包含\"垃圾\"值，这是之前在同一内存位置存储的旧数据。尝试读取或操作这些值可能会产生未定义的结果，因为你不能确定这些内存的内容。 程序崩溃或异常行为：如果未初始化的内存用于控制程序流程（例如，作为决定分支或循环的条件），程序可能会以意外的方式行为，甚至崩溃。 安全问题：如果未初始化的内存内容被外部用户访问，可能会导致一些敏感信息的泄露。另一方面，如果用户能够以某种方式影响未初始化的内存的内容，那他们可能在运行时改变程序的行为。 数据错误：如果未初始化的内存用于存储应用的数据，可能导致数据错误或者数据损坏。 Go语言通过自动初始化变量的方式，为未初始化的变量赋予一个确定的零值，有效地消除了以上这些由未初始化内存带来的问题。 ","date":"2024-02-21","objectID":"/go-%E5%86%85%E5%AD%98%E5%AE%89%E5%85%A8/:1:0","tags":["go"],"title":"go 内存安全","uri":"/go-%E5%86%85%E5%AD%98%E5%AE%89%E5%85%A8/"},{"categories":null,"content":"关于","date":"2024-01-01","objectID":"/about/","tags":null,"title":"关于","uri":"/about/"}]